import os
import fitz  # PyMuPDF
import docx
import pytesseract
from PIL import Image
from io import BytesIO
from google.cloud import aiplatform
from langchain import LLMChain
from vertexai import TextEmbeddingModel

# Initialize Google Cloud Vertex AI
aiplatform.init(project='YOUR_PROJECT_ID', location='YOUR_REGION')

# Function to extract text from images using OCR
def ocr_image(image):
    return pytesseract.image_to_string(image)

# Function to read PDF and extract text and images
def read_pdf(file_path):
    doc = fitz.open(file_path)
    text = ""
    for page in doc:
        text += page.get_text()
        for img in page.get_images(full=True):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            image = Image.open(BytesIO(image_bytes))
            text += ocr_image(image)
    return text

# Function to read DOCX and extract text and images
def read_docx(file_path):
    doc = docx.Document(file_path)
    text = ""
    for para in doc.paragraphs:
        text += para.text
    for rel in doc.part.rels:
        if "image" in doc.part.rels[rel].target_ref:
            image = doc.part.rels[rel].target_part.blob
            image = Image.open(BytesIO(image))
            text += ocr_image(image)
    return text

# Function to read TXT
def read_txt(file_path):
    with open(file_path, 'r') as file:
        text = file.read()
    return text

# Function to read files in a folder
def read_documents(folder_path):
    documents = []
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if filename.endswith('.pdf'):
            documents.append(read_pdf(file_path))
        elif filename.endswith('.docx'):
            documents.append(read_docx(file_path))
        elif filename.endswith('.txt'):
            documents.append(read_txt(file_path))
    return documents

# Function to create embeddings using Vertex AI
def create_embeddings(text):
    model = TextEmbeddingModel.from_pretrained("YOUR_VERTEX_AI_EMBEDDING_MODEL_NAME")
    response = model.predict(text)
    return response.embeddings

# Vertex AI model prediction function
def predict_with_vertex_ai(prompt):
    model = aiplatform.TextGenerationModel.from_pretrained("YOUR_VERTEX_AI_MODEL_NAME")
    response = model.predict(prompt)
    return response

# LangChain setup
class VertexAILLMChain(LLMChain):
    def __init__(self):
        super().__init__()

    def __call__(self, prompt):
        return predict_with_vertex_ai(prompt)

# Main chatbot function
def chatbot(folder_path, user_input):
    documents = read_documents(folder_path)
    context = " ".join(documents)  # Combine documents into a single context
    context_embeddings = create_embeddings(context)  # Create embeddings for the context
    chain = VertexAILLMChain()
    prompt = f"Context: {context}\nUser: {user_input}\nBot:"
    response = chain(prompt)
    return response

# Example usage
folder_path = 'path_to_your_documents_folder'
user_input = "Ask your question here"
response = chatbot(folder_path, user_input)
print(response)
