{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c99e35-32aa-4c03-8073-1d36e9e9823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import mammoth\n",
    "import numpy as np\n",
    "from docx import Document as DocxDocument\n",
    "from langchain.docstore.document import Document\n",
    "from openpyxl import load_workbook\n",
    "import PyPDF2\n",
    "import fitz\n",
    "import xlrd\n",
    "import subprocess\n",
    "from langchain.embeddings.vertexai import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c19063-6445-4e92-ba8f-cb67c1f291f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                text += pdf_reader.pages[page_num].extract_text()\n",
    "    except:\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = DocxDocument(file_path)\n",
    "    return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "\n",
    "def read_docm(file_path):\n",
    "    with open(file_path, 'rb') as docm_file:\n",
    "        result = mammoth.extract_raw_text(docm_file)\n",
    "        return result.value\n",
    "\n",
    "\n",
    "def read_xls(file_path):\n",
    "    workbook = xlrd.open_workbook(file_path)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = []\n",
    "    for row_num in range(sheet.nrows):\n",
    "        data.append(\"\\t\".join(map(str, sheet.row_values(row_num))))\n",
    "    return \"\\n\".join(data)\n",
    "\n",
    "\n",
    "def read_xlsx(file_path):\n",
    "    workbook = load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        data.append(\"\\t\".join(map(str, row)))\n",
    "    return \"\\n\".join(data)\n",
    "\n",
    "\n",
    "def read_doc(file_path):\n",
    "    result = subprocess.run(['antiword', file_path], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        raise Exception(f\"Error reading {file_path}: {result.stderr}\")\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "def load_files(directory):\n",
    "    documents = []\n",
    "    unread_documents = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=350)\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            if filename.endswith('.txt'):\n",
    "                content = read_txt(file_path)\n",
    "            elif filename.endswith('.pdf'):\n",
    "                content = read_pdf(file_path)\n",
    "            elif filename.endswith('.docx'):\n",
    "                content = read_docx(file_path)\n",
    "            elif filename.endswith('.doc'):\n",
    "                content = read_doc(file_path)\n",
    "            elif filename.endswith('.docm'):\n",
    "                content = read_docm(file_path)\n",
    "            elif filename.endswith('.xls'):\n",
    "                content = read_xls(file_path)\n",
    "            elif filename.endswith('.xlsx'):\n",
    "                content = read_xlsx(file_path)\n",
    "            else:\n",
    "                print(f\"Unsupported file format: {filename}\")\n",
    "                unread_documents.append(filename)\n",
    "                continue\n",
    "            doc = Document(page_content=content, metadata={\"filename\": filename})\n",
    "            split_docs = text_splitter.split_documents([doc])\n",
    "            documents.extend(split_docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "            unread_documents.append(filename)\n",
    "    return documents, unread_documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35a6499-e519-4afc-bd67-4fc0403b662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process Aerial Service Wire (ASW) Process All Markets-Copy1.docx: \"There is no item named 'word/NULL' in the archive\"\n",
      "Unsupported file format: Tekelec - fru-square-fan.mpg\n",
      "Failed to process Central Office Power - Power Routine Forms - all.xlsx: Unable to read workbook: could not read strings from /home/jupyter/DarkDawn/sp_docs/Central Office Power - Power Routine Forms - all.xlsx.\n",
      "This is most probably because the workbook source files contain some invalid XML.\n",
      "Please see the exception for more details.\n",
      "Unsupported file format: Adtran TA5000 Cobmbo VDSL 2 Tech Bulletin 61187120L1-4D.PDF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/openpyxl/reader/drawings.py:63: UserWarning: wmf image format is not supported so the image is being dropped\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: Ciena  - Champion SFP+.pptx\n",
      "Unsupported file format: Calix C7 Ethernet Services Presentation.pptx\n",
      "Unsupported file format: Tellabs Update - GbE Guidelines 5.12.11 Installation.pptx\n",
      "Unsupported file format: dont_touch.pkl\n",
      "Failed to process A2EProposedProjectActivity.xlsx: File is not a zip file\n",
      "Unsupported file format: Adtran TA 5004 Hi Level Overview.pptx\n",
      "Failed to process ADTRAN Internal ONTs Installation and Maintenance Guidelines.docx: \"There is no item named 'word/NULL' in the archive\"\n",
      "Unsupported file format: E911-Translations.ppt\n",
      "Unsupported file format: Tellabs 530 531 532 Database backups.pptx\n",
      "Failed to process TA5000-TA5006 BBDLC RT Node Provisioning Job Aid 6-10-11 SR 5-0.1.1.doc: 'utf-8' codec can't decode byte 0xed in position 83816: invalid continuation byte\n",
      "Unsupported file format: Calix - G FAST -  Activate Training 2-12-2018 - Copy.pptx\n",
      "Unsupported file format: Adtran TA1124 ntwk power block diagrams 1.ppt\n",
      "Unsupported file format: Adtran TA5000 Technical Bulletin.PDF\n",
      "Failed to process ADTRAN External Rated ONT TA352, TA362, TA362S, TA372, TA374 Installation $ Maintenance.docx: \"There is no item named 'word/NULL' in the archive\"\n",
      "Unsupported file format: Albercorp - CRT 400 basics.ppsx\n",
      "Failed to process TA5000-TA5006 BBDLC CO Node Provisioning Job Aid 6-10-11 SR 5-0.1.1.doc: 'utf-8' codec can't decode byte 0xed in position 60052: invalid continuation byte\n",
      "Unsupported file format: Tekelec - replace_filter.mpg\n",
      "Failed to process Adtran_Transitional_Device_Config_Template.xlsx: File is not a zip file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported file format: Tellabs 1000 FP15-Transport Guidelines.pptx\n",
      "Failed to process Aerial Service Wire (ASW) Process All Markets.docx: \"There is no item named 'word/NULL' in the archive\"\n",
      "Unsupported file format: .ipynb_checkpoints\n",
      "Failed to process Calix_Transitional_Device_Config_Template.xlsx: File is not a zip file\n",
      "Failed to process Tellabs AFC_UMC1000_Transitional_Device.xlsx: File is not a zip file\n",
      "Unsupported file format: Tekelec - replace_fans.mpg\n"
     ]
    }
   ],
   "source": [
    "directory = '/home/jupyter/DarkDawn/sp_docs'\n",
    "\n",
    "# 5208 seconds\n",
    "documents, unread = load_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203cbfc3-bbb0-4874-9cad-a11acf9d0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathh='documents_obj.pkl'\n",
    "with open(pathh, 'wb') as f:\n",
    "    pickle.dump(documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1a146d-1161-480f-92a2-1ba4f645a06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Fiber + Birth Certificates Tool (DS/CO)\\n\\n\\n\\n\\nRelated Documents\\n\\n\\n\\nThe fiber plus birth certificates tool will: \\n\\nProvide customer with written confirmation of successful delivery of service.\\nProvide detailed record of successful install, including date/time stamp for internal records; date service was delivered and tested.\\nValidate data throughput meets parameters of bandwidth purchased by customer.\\nPrompt the customer to formally accept the service on the day of service delivery. \\nIf customer does not provide acceptance, the Birth Certificate will trigger closure of the National Order MLAP job, and move order to billing\\nProvide customer with their Circuit ID, and CenturyLink contact information needed for repair/service calls\\nNotify Project Managers working Hosted VOIP/Managed Office orders, of completion of the transport component, allowing them to schedule the HV/MO installation\\nReduce dispatches to customer premises to validate service\\n\\n\\nPerformance Testing and Birth Certificate Tool Usage\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearching Completed Birth Certificate Forms \\n\\nThe field can access the Submissions site and search for completed forms, as needed.  Follow the steps below: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nField Supervisors, Managers, and Regional Analysts can also request to receive a bi-weekly email including a spreadsheet that can be filtered. All requests should be sent to Bob Simmons at Bob Simmons.  \\n\\nSee example of the spreadsheet below.', metadata={'filename': 'Fiber + Birth Certificates Tool (All Markets).docx'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81475fa-04d8-4ea1-ba49-a7e8176de76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "local-conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
